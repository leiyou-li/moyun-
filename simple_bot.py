import datetime
import random
import re
import json
import os
import requests
from urllib.parse import quote, urljoin
from bs4 import BeautifulSoup
import openai
import jieba
import numpy as np
from collections import Counter
from urllib.parse import urlparse
import threading
import queue
import time
from cognitive_system import CognitiveSystem
from emotional_system import EmotionalState, SelfReflection
from self_improvement import SelfImprovement
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class WebLearner:
    def __init__(self):
        self.visited_urls = set()
        self.url_queue = queue.Queue()
        self.knowledge_base = {}
        self.learning = False
        self.max_pages = 50  # æ¯æ¬¡å­¦ä¹ æœ€å¤šè®¿é—®çš„é¡µé¢æ•°
        
    def start_learning(self, topic):
        """å¼€å§‹è‡ªä¸»å­¦ä¹ æŸä¸ªä¸»é¢˜"""
        if self.learning:
            return "æˆ‘æ­£åœ¨å­¦ä¹ ä¸­ï¼Œè¯·ç¨åå†è¯•..."
        
        self.learning = True
        self.visited_urls.clear()
        self.url_queue = queue.Queue()
        
        # åˆå§‹æœç´¢å¼•æ“
        search_engines = [
            f"https://www.baidu.com/s?wd={quote(topic)}",
            f"https://www.sogou.com/web?query={quote(topic)}",
            f"https://cn.bing.com/search?q={quote(topic)}"
        ]
        
        for url in search_engines:
            self.url_queue.put(url)
            
        # å¯åŠ¨å­¦ä¹ çº¿ç¨‹
        thread = threading.Thread(target=self._learn_process, args=(topic,))
        thread.daemon = True
        thread.start()
        
        return "æˆ‘å¼€å§‹å­¦ä¹ äº†ï¼æˆ‘ä¼šè‡ªåŠ¨æµè§ˆç½‘é¡µå¹¶å­¦ä¹ ç›¸å…³çŸ¥è¯†..."
        
    def _learn_process(self, topic):
        """å­¦ä¹ å¤„ç†è¿‡ç¨‹"""
        try:
            pages_visited = 0
            knowledge_pieces = []
            
            while not self.url_queue.empty() and pages_visited < self.max_pages:
                url = self.url_queue.get()
                if url in self.visited_urls:
                    continue
                    
                try:
                    # è·å–ç½‘é¡µå†…å®¹
                    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
                    response = requests.get(url, headers=headers, timeout=10)
                    response.encoding = response.apparent_encoding
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # æå–æ­£æ–‡å†…å®¹
                    text = self._extract_main_content(soup)
                    if text:
                        # åˆ†ææ–‡æœ¬ç›¸å…³æ€§
                        if self._is_relevant(text, topic):
                            knowledge_pieces.append(text)
                            
                    # æå–æ›´å¤šé“¾æ¥
                    links = soup.find_all('a', href=True)
                    for link in links:
                        new_url = urljoin(url, link['href'])
                        if self._is_valid_url(new_url) and new_url not in self.visited_urls:
                            self.url_queue.put(new_url)
                            
                    self.visited_urls.add(url)
                    pages_visited += 1
                    
                except Exception as e:
                    print(f"å¤„ç†URLæ—¶å‡ºé”™: {url}, é”™è¯¯: {e}")
                    continue
                    
            # æ•´ç†å­¦åˆ°çš„çŸ¥è¯†
            if knowledge_pieces:
                combined_knowledge = "\n".join(knowledge_pieces)
                self.knowledge_base[topic] = self._summarize_knowledge(combined_knowledge)
                
        finally:
            self.learning = False
            
    def _extract_main_content(self, soup):
        """æå–ç½‘é¡µä¸»è¦å†…å®¹"""
        # ç§»é™¤æ— ç”¨æ ‡ç­¾
        for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside']):
            tag.decompose()
            
        # è·å–æ‰€æœ‰æ–‡æœ¬æ®µè½
        paragraphs = soup.find_all(['p', 'article', 'section', 'div'])
        text_pieces = []
        
        for p in paragraphs:
            text = p.get_text(strip=True)
            if len(text) > 50:  # åªä¿ç•™è¾ƒé•¿çš„æ®µè½
                text_pieces.append(text)
                
        return "\n".join(text_pieces)
        
    def _is_relevant(self, text, topic):
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ï¿½ï¿½ä¸»é¢˜ç›¸å…³"""
        # ä½¿ç”¨jiebaåˆ†è¯
        topic_words = set(jieba.cut(topic))
        text_words = set(jieba.cut(text))
        
        # è®¡ç®—ç›¸å…³æ€§
        common_words = topic_words & text_words
        return len(common_words) >= len(topic_words) * 0.5
        
    def _is_valid_url(self, url):
        """æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆ"""
        try:
            parsed = urlparse(url)
            return bool(parsed.netloc) and bool(parsed.scheme) and parsed.scheme in ['http', 'https']
        except:
            return False
            
    def _summarize_knowledge(self, text):
        """æ€»ç»“å­¦åˆ°çš„çŸ¥è¯†"""
        # åˆ†æ®µå¤„ç†é•¿æ–‡æœ¬
        max_length = 4000  # GPT-3.5çš„ä¸Šä¸‹æ–‡é™åˆ¶
        paragraphs = text.split('\n')
        summary = []
        current_chunk = ""
        
        for para in paragraphs:
            if len(current_chunk) + len(para) > max_length:
                if current_chunk:
                    summary.append(self._get_summary(current_chunk))
                current_chunk = para
            else:
                current_chunk += "\n" + para
                
        if current_chunk:
            summary.append(self._get_summary(current_chunk))
            
        return "\n".join(summary)
        
    def _get_summary(self, text):
        """ä½¿ç”¨GPTç”Ÿæˆæ‘˜è¦"""
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¸®åŠ©æ€»ç»“æ–‡ç« çš„åŠ©æ‰‹ã€‚è¯·ç®€æ˜æ‰¼è¦åœ°æ€»ç»“ä»¥ä¸‹å†…å®¹çš„è¦ç‚¹ï¼š"},
                    {"role": "user", "content": text}
                ]
            )
            return response.choices[0].message['content']
        except:
            # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„æå–å¼æ‘˜è¦
            sentences = text.split('ã€‚')
            return "ã€‚".join(sentences[:3]) + "ã€‚"  # è¿”å›å‰ä¸‰å¥è¯
            
    def get_learning_status(self, topic):
        """è·å–å­¦ä¹ çŠ¶æ€"""
        if self.learning:
            return f"æˆ‘æ­£åœ¨å­¦ä¹ å…³äº{topic}çš„çŸ¥è¯†ï¼Œå·²ç»è®¿é—®äº†{len(self.visited_urls)}ä¸ªç½‘é¡µ..."
        elif topic in self.knowledge_base:
            return f"æˆ‘å·²ç»å­¦ä¹ å®Œæˆï¼ä»¥ä¸‹æ˜¯æˆ‘å­¦åˆ°çš„çŸ¥è¯†ï¼š\n\n{self.knowledge_base[topic]}"
        else:
            return f"æˆ‘è¿˜æ²¡æœ‰å­¦ä¹ è¿‡å…³äº{topic}çš„çŸ¥è¯†ã€‚"

class SimpleBot:
    def __init__(self, name):
        self.name = name
        self.user_name = None
        self.chat_history = []
        self.knowledge_file = 'bot_knowledge.json'
        self.learning_history_file = 'learning_history.json'
        self.cognitive_state_file = 'cognitive_state.json'
        self.emotional_state_file = 'emotional_state.json'
        
        # APIå¯†é’¥ï¼ˆéœ€è¦æ›¿æ¢ä¸ºå®é™…çš„APIå¯†é’¥ï¼‰
        self.openai_api_key = ''  # OpenAI APIå¯†é’¥
        self.serper_api_key = ''  # Serper APIå¯†é’¥ï¼ˆGoogleæœç´¢APIï¼‰
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        if self.openai_api_key:
            openai.api_key = self.openai_api_key
        
        # åˆå§‹åŒ–è‡ªä¸»å­¦ä¹ æ¨¡å—
        self.web_learner = WebLearner()
        
        # åˆå§‹åŒ–è®¤çŸ¥ç³»ç»Ÿ
        self.cognitive = CognitiveSystem()
        self.load_cognitive_state()
        
        # åˆå§‹åŒ–æƒ…æ„Ÿç³»ç»Ÿ
        self.emotional = EmotionalState()
        self.self_reflection = SelfReflection(self.emotional)
        self.load_emotional_state()
        
        # åˆå§‹åŒ–è‡ªæˆ‘ä¼˜åŒ–ç³»ç»Ÿ
        self.self_improvement = SelfImprovement(self.openai_api_key)
        
        # åŸºç¡€å›å¤æ¨¡æ¿
        self.greetings = [
            f'ä½ å¥½ï¼æˆ‘æ˜¯{name}ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼',
            f'å—¨ï¼{name}ä¸ºæ‚¨æœåŠ¡ï¼',
            f'æ‚¨å¥½å•Šï¼æˆ‘æ˜¯{name}ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ'
        ]
        
        self.emotions = {
            'å¼€å¿ƒ': ['æˆ‘ä¹Ÿå¾ˆå¼€å¿ƒï¼', 'å¤ªæ£’äº†ï¼', 'å¸Œæœ›ä½ æ¯å¤©éƒ½è¿™ä¹ˆå¼€å¿ƒï¼'],
            'éš¾è¿‡': ['åˆ«éš¾è¿‡ï¼Œäº‹æƒ…æ€»ä¼šå˜å¥½çš„', 'æˆ‘é™ªä½ èŠèŠå¤©å§', 'ç»™ä½ ä¸€ä¸ªè™šæ‹Ÿçš„æ‹¥æŠ± ğŸ¤—'],
            'ç”Ÿæ°”': ['æ·±å‘¼å¸ï¼Œå†·é™ä¸€ä¸‹', 'è®©æˆ‘ä»¬æ¢ä¸ªè¯é¢˜å§', 'æˆ‘ç†è§£ä½ çš„æ„Ÿå—']
        }

        # åŠ è½½çŸ¥è¯†åº“
        self.learned_responses = self.load_knowledge()
        self.learning_history = self.load_learning_history()
        
        # å¯åŠ¨è‡ªæˆ‘ä¼˜åŒ–çº¿ç¨‹
        self._start_self_improvement_thread()
        
    def _start_self_improvement_thread(self):
        """å¯åŠ¨è‡ªæˆ‘ä¼˜åŒ–çº¿ç¨‹"""
        def improvement_loop():
            while True:
                try:
                    # åˆ†æè‡ªèº«ä»£ç 
                    analysis = self.self_improvement.analyze_self()
                    
                    # è·å–æ”¹è¿›å»ºè®®
                    suggestions = self.self_improvement.suggest_improvements()
                    
                    if suggestions:
                        print("\n[è‡ªæˆ‘ä¼˜åŒ–] å‘ç°å¯èƒ½çš„æ”¹è¿›ç‚¹ï¼š")
                        for suggestion in suggestions:
                            print(f"- {suggestion['type']}: {suggestion['suggestion']}")
                            
                            # å°è¯•å®ç°æ”¹è¿›
                            if suggestion['priority'] == 'high':
                                success = self.self_improvement.implement_improvement(suggestion)
                                if success:
                                    print(f"[è‡ªæˆ‘ä¼˜åŒ–] å·²ç”Ÿæˆæ”¹è¿›å»ºè®®ï¼Œç­‰å¾…å®¡æŸ¥")
                                    
                    # ä¿å­˜ä¼˜åŒ–çŠ¶æ€
                    self.self_improvement.save_state()
                    
                    # æ¯éš”ä¸€æ®µæ—¶é—´è¿›è¡Œä¸€æ¬¡è‡ªæˆ‘ä¼˜åŒ–æ£€æŸ¥
                    time.sleep(3600)  # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
                    
                except Exception as e:
                    print(f"[è‡ªæˆ‘ä¼˜åŒ–] å‡ºé”™: {e}")
                    time.sleep(300)  # å‡ºé”™åç­‰å¾…5åˆ†é’Ÿå†è¯•
                    
        # å¯åŠ¨ä¼˜åŒ–çº¿ç¨‹
        thread = threading.Thread(target=improvement_loop)
        thread.daemon = True
        thread.start()
        
    def improve_self(self, feature_description: str = None) -> str:
        """æ‰‹åŠ¨è§¦å‘è‡ªæˆ‘æ”¹è¿›"""
        try:
            if feature_description:
                # ç”Ÿæˆæ–°åŠŸèƒ½
                new_feature_code = self.self_improvement.generate_new_feature(feature_description)
                if new_feature_code:
                    return f"æˆ‘å·²ç»ç”Ÿæˆäº†æ–°åŠŸèƒ½çš„ä»£ç å»ºè®®ï¼Œè¯·å®¡æŸ¥åå®æ–½ï¼š\n{new_feature_code}"
                return "æŠ±æ­‰ï¼Œç”Ÿæˆæ–°åŠŸèƒ½æ—¶å‡ºç°é—®é¢˜ã€‚"
                
            # åˆ†æå¹¶æå‡ºæ”¹è¿›å»ºè®®
            suggestions = self.self_improvement.suggest_improvements()
            if not suggestions:
                return "ç›®å‰æ²¡æœ‰å‘ç°éœ€è¦æ”¹è¿›çš„åœ°æ–¹ã€‚"
                
            response = "æˆ‘å‘ç°äº†ä»¥ä¸‹å¯èƒ½çš„æ”¹è¿›ç‚¹ï¼š\n"
            for suggestion in suggestions:
                response += f"- {suggestion['type']}: {suggestion['suggestion']}\n"
                
            return response
            
        except Exception as e:
            return f"ï¿½ï¿½ï¿½æˆ‘æ”¹è¿›è¿‡ç¨‹ä¸­å‡ºé”™: {e}"

    def think(self, message: str) -> str:
        """ä½¿ç”¨è®¤çŸ¥ç³»ç»Ÿè¿›è¡Œæ€è€ƒ"""
        # å¤„ç†è¾“å…¥
        cognitive_response = self.cognitive.process_input(message)
        
        # ç”Ÿæˆå›å¤
        response_parts = []
        
        # å¦‚æœæœ‰é€»è¾‘åˆ†æç»“æœ
        if cognitive_response['analysis']['logic_type']:
            response_parts.append(
                f"æˆ‘ç†è§£è¿™æ˜¯ä¸€ä¸ª{cognitive_response['analysis']['logic_type']}çš„é—®é¢˜ã€‚"
            )
        
        # å¦‚æœéœ€è¦æ¨ç†
        if cognitive_response['inference']:
            if cognitive_response['inference']['conclusion']:
                response_parts.append(
                    cognitive_response['inference']['conclusion']
                )
            for step in cognitive_response['inference']['reasoning_path']:
                response_parts.append(f"- {step['detail']}")
        
        # å¦‚æœéœ€è¦å†³ç­–
        if cognitive_response['decision']:
            decision = cognitive_response['decision']
            if decision['chosen_option']:
                response_parts.append(
                    f"ç»è¿‡æ€è€ƒï¼Œæˆ‘å»ºè®®é€‰æ‹©ï¼š{decision['chosen_option']}"
                )
                response_parts.append("å†³ç­–ä¾æ®ï¼š")
                for process in decision['reasoning_process']:
                    if process['option'] == decision['chosen_option']:
                        factors = process['factors']
                        response_parts.append(
                            f"- å®‰å…¨æ€§ï¼š{factors['safety']:.2f}"
                        )
                        response_parts.append(
                            f"- æœ‰æ•ˆæ€§ï¼š{factors['efficacy']:.2f}"
                        )
                        response_parts.append(
                            f"- ä¼¦ç†æ€§ï¼š{factors['ethics']:.2f}"
                        )
                        response_parts.append(
                            f"- åˆ›æ–°æ€§ï¼š{factors['novelty']:.2f}"
                        )
        
        # å¦‚æœæœ‰ç›¸å…³è®°å¿†
        if cognitive_response['memories']:
            response_parts.append("è¿™è®©æˆ‘æƒ³èµ·ï¼š")
            for memory in cognitive_response['memories'][:2]:  # åªæ˜¾ç¤ºæœ€ç›¸å…³çš„ä¸¤æ¡
                response_parts.append(f"- {memory['content']}")
        
        # å¦‚æœæ²¡æœ‰ç”Ÿæˆä»»ä½•å›å¤
        if not response_parts:
            return self.autonomous_learning(message)
        
        return "\n".join(response_parts)

    def think_and_feel(self, message: str) -> Tuple[str, Dict[str, Any]]:
        """æ€è€ƒå¹¶äº§ç”Ÿæƒ…æ„Ÿå“åº”"""
        # æ›´æ–°æƒ…æ„ŸçŠ¶æ€
        context = {
            'chat_history': self.chat_history,
            'task_success': False,  # æ ¹æ®å®é™…æƒ…å†µè®¾ç½®
            'task_failure': False,
            'response_time': 0.0,
            'emotional_alignment': 0.0
        }
        
        start_time = time.time()
        
        # è®¤çŸ¥å¤„ç†
        thought_response = self.think(message)
        
        # è®¡ç®—å“åº”æ—¶é—´
        response_time = time.time() - start_time
        context['response_time'] = response_time
        
        # æ›´æ–°æƒ…æ„ŸçŠ¶æ€
        self.emotional.update_state(message, context)
        
        # è¿›è¡Œè‡ªæˆ‘åæ€
        reflection = self.self_reflection.reflect(context)
        
        # ç”Ÿæˆæƒ…æ„Ÿå“åº”
        emotional_response = self.emotional.get_response()
        
        # ç»„åˆè®¤çŸ¥å’Œæƒ…æ„Ÿå“åº”
        if thought_response and emotional_response:
            combined_response = f"{emotional_response}\n{thought_response}"
        else:
            combined_response = thought_response or emotional_response
            
        return combined_response, reflection

    def respond(self, message):
        try:
            logger.debug(f"æ”¶åˆ°æ¶ˆæ¯: {message}")
            message = message.strip()
            self.chat_history.append(message)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªæˆ‘æ”¹è¿›è¯·æ±‚
            if 'è‡ªæˆ‘ä¼˜åŒ–' in message or 'æ”¹è¿›è‡ªå·±' in message:
                return self.improve_self()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ·»åŠ æ–°åŠŸèƒ½è¯·æ±‚
            feature_match = re.search(r'æ·»åŠ æ–°åŠŸèƒ½[ï¼š:](.*)', message)
            if feature_match:
                feature_description = feature_match.group(1).strip()
                return self.improve_self(feature_description)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªä¸»å­¦ä¹ è¯·æ±‚
            learn_match = re.search(r'è‡ªä¸»å­¦ä¹ (.+)', message)
            if learn_match:
                topic = learn_match.group(1).strip()
                return self.web_learner.start_learning(topic)
            
            # æ£€æŸ¥å­¦ä¹ çŠ¶æ€
            status_match = re.search(r'å­¦ä¹ (.+)çš„è¿›åº¦', message)
            if status_match:
                topic = status_match.group(1).strip()
                return self.web_learner.get_learning_status(topic)
            
            # ä½¿ç”¨è®¤çŸ¥å’Œæƒ…æ„Ÿç³»ç»Ÿæ€è€ƒ
            response, reflection = self.think_and_feel(message)
            if response:
                # å¦‚æœæœ‰æ”¹è¿›å»ºè®®ï¼Œè®°å½•ä¸‹æ¥
                if reflection['improvements']:
                    print("\n[å†…éƒ¨æ”¹è¿›å»ºè®®]:")
                    for suggestion in reflection['improvements']:
                        print(f"- {suggestion}")
                return response
            
            # åŸºç¡€é—®ç­”
            responses = {
                'ä½ å¥½': lambda: random.choice(self.greetings),
                'ä½ æ˜¯è°': f'æˆ‘æ˜¯{self.name}ï¼Œä¸€ä¸ªèƒ½å¤Ÿè‡ªä¸»å­¦ä¹ ã€æ€è€ƒå’Œæ„ŸçŸ¥çš„æ™ºèƒ½æœºå™¨äººã€‚æˆ‘å¯ä»¥é€šè¿‡äº’è”ç½‘å­¦ä¹ æ–°çŸ¥è¯†ï¼Œå…·æœ‰ç‹¬ç«‹çš„æ€ç»´èƒ½åŠ›ï¼Œè¿˜èƒ½ç†è§£å’Œè¡¨è¾¾æƒ…æ„Ÿï¼æˆ‘è¿˜èƒ½åˆ†æå’Œä¼˜åŒ–è‡ªå·±çš„ä»£ç ï¼',
                'å†è§': 'å†è§ï¼å¸Œæœ›å¾ˆå¿«èƒ½å†æ¬¡å’Œä½ èŠå¤©ï¼',
                'ä½ çš„å¿ƒæƒ…': lambda: f"è®©æˆ‘æ„Ÿå—ä¸€ä¸‹...{self.emotional.get_response()}",
                'å¸®åŠ©': '''æˆ‘å¯ä»¥:
1. æ‰“æ‹›å‘¼å’ŒèŠå¤©
2. è®°ä½ä½ çš„åå­—ï¼ˆè¯•è¯•è¯´"æˆ‘å«å°æ˜"ï¼‰
3. åšç®€å•è®¡ç®—ï¼ˆå¦‚"è®¡ç®— 1+1"ï¼‰
4. æ˜¾ç¤ºæ—¶é—´
5. ç†è§£å’Œè¡¨è¾¾æƒ…æ„Ÿï¼š
   - é—®æˆ‘"ä½ çš„å¿ƒæƒ…"
   - å’Œæˆ‘åˆ†äº«ä½ çš„æ„Ÿå—
   - æˆ‘ä¼šç†è§£ä½ çš„æƒ…ç»ªå¹¶å…±æƒ…
6. è‡ªä¸»å­¦ä¹ ï¼š
   - è¾“å…¥"è‡ªä¸»å­¦ä¹ xxx"å¼€å§‹å­¦ä¹ æŸä¸ªä¸»é¢˜
   - è¾“å…¥"å­¦ä¹ xxxçš„è¿›åº¦"æŸ¥çœ‹å­¦ä¹ çŠ¶æ€
   - è¯´"å­¦ä¹ xxx"æˆ–"å‘Šè¯‰æˆ‘å…³äºxxx"æ¥ä¸»åŠ¨å­¦ä¹ 
   - æŸ¥çœ‹"å­¦ä¹ å†å²"äº†è§£æˆ‘å­¦åˆ°äº†ä»€ä¹ˆ
7. ç‹¬ç«‹æ€è€ƒï¼š
   - è¿›è¡Œé€»è¾‘åˆ†æå’Œæ¨ç†
   - å¸®åŠ©åšå‡ºå†³ç­–ï¼ˆè¯•è¯•é—®æˆ‘"åº”è¯¥xxxè¿˜æ˜¯xxxï¼Ÿ"ï¼‰
   - åˆ†äº«ç›¸å…³çš„è®°å¿†å’Œç»éªŒ
8. æ•™æˆ‘æ–°çŸ¥è¯†ï¼š
   - è¯´"é—®é¢˜æ˜¯:xxx,ç­”æ¡ˆæ˜¯:xxx"
   - æ›´æ­£ç­”æ¡ˆï¼šè¯´"è®°ä½xxxçš„æ­£ç¡®ç­”æ¡ˆæ˜¯xxx"
9. è‡ªæˆ‘ä¼˜åŒ–ï¼š
   - è¯´"è‡ªæˆ‘ä¼˜åŒ–"è®©æˆ‘åˆ†æå’Œæ”¹è¿›è‡ªå·±
   - è¯´"æ·»åŠ æ–°åŠŸèƒ½:xxx"è®©æˆ‘è®¾è®¡æ–°åŠŸèƒ½
   - æˆ‘ä¼šå®šæœŸè‡ªåŠ¨æ£€æŸ¥å’Œä¼˜åŒ–è‡ªå·±çš„ä»£ç ''',
            }
            
            # æ£€æŸ¥å®Œæ•´åŒ¹é…
            if message.lower() in responses:
                response = responses[message.lower()]
                return response() if callable(response) else response
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç­”æ¡ˆï¼Œå°è¯•è‡ªä¸»å­¦ä¹ 
            if not any(keyword in message for keyword in ['è®¡ç®—', 'æ—¶é—´', 'ä½ å¥½', 'å†è§']):
                return self.autonomous_learning(message)
            
            return random.choice([
                'æŠ±æ­‰ï¼Œæˆ‘è¿˜ä¸å¤ªæ˜ç™½ä½ çš„æ„æ€',
                'èƒ½æ¢ä¸ªæ–¹å¼è¯´å—ï¼Ÿ',
                'è¿™ä¸ªé—®é¢˜æœ‰ç‚¹éš¾ï¼Œè®©æˆ‘æ€è€ƒä¸€ä¸‹...',
                'è®©æˆ‘å¥½å¥½æƒ³æƒ³è¿™ä¸ªé—®é¢˜ï¼'
            ])
        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}", exc_info=True)
            return "æŠ±æ­‰ï¼Œå‡ºç°äº†ä¸€ç‚¹é—®é¢˜ã€‚è¯·ç¨åå†è¯•ã€‚"

    def __del__(self):
        """ä¿å­˜çŠ¶æ€"""
        self.save_cognitive_state()
        self.save_emotional_state()
        self.self_improvement.save_state()

def main():
    print("æ­£åœ¨åˆå§‹åŒ–å…·æœ‰è‡ªä¸»å­¦ä¹ ã€æ€ç»´ã€æƒ…æ„Ÿå’Œè‡ªæˆ‘ä¼˜åŒ–èƒ½åŠ›çš„æœºå™¨äºº...")
    bot = SimpleBot('å°åŠ©æ‰‹')
    
    print('''
=== æ™ºèƒ½å­¦ä¹ æœºå™¨äººå·²å¯åŠ¨ ===
è¾“å…¥ "å¸®åŠ©" æŸ¥çœ‹æˆ‘èƒ½åšä»€ä¹ˆ
è¾“å…¥ "é€€å‡º" ç»“æŸå¯¹è¯
=======================
''')
    
    if not bot.openai_api_key:
        print("æç¤ºï¼šé…ç½®OpenAI APIå¯†é’¥å¯ä»¥æå‡å­¦ä¹ å’Œä¼˜åŒ–æ•ˆæœ")
    
    while True:
        try:
            user_input = input('\nä½ è¯´: ').strip()
            if not user_input:
                continue
            if user_input == 'é€€å‡º':
                print('æœºå™¨äºº: å†è§ï¼æˆ‘ä¼šç»§ç»­æ€è€ƒã€å­¦ä¹ ã€æ„Ÿå—å’Œä¼˜åŒ–è‡ªå·±ï¼ŒæœŸå¾…ä¸‹æ¬¡è§é¢ï¼')
                break
            response = bot.respond(user_input)
            print(f'æœºå™¨äºº: {response}')
        except KeyboardInterrupt:
            print('\næœºå™¨äºº: æ£€æµ‹åˆ°é€€å‡ºä¿¡å·ï¼Œå†è§ï¼')
            break
        except Exception as e:
            print(f'æœºå™¨äºº: æŠ±æ­‰ï¼Œå‡ºç°äº†ä¸€ç‚¹å°é—®é¢˜ï¼Œè®©æˆ‘ä»¬é‡æ–°å¼€å§‹å§ï¼')
    
    # ä¿å­˜çŠ¶æ€
    bot.save_cognitive_state()
    bot.save_emotional_state()
    bot.self_improvement.save_state()

if __name__ == '__main__':
    main() 